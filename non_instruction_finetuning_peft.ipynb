{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPTm7vscAIR0IwNRf57nN+U",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b9f6c256c99c482fbaefdfe3be2cfd7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5bdb01c4383d46aebdaa221dbc6c752d",
              "IPY_MODEL_6966a83400484080ab10c8e871a27fbf",
              "IPY_MODEL_b0f82745646e4d5db681e68e73442796"
            ],
            "layout": "IPY_MODEL_227c873e3a4c4f3c8e3a51a4c745a27b"
          }
        },
        "5bdb01c4383d46aebdaa221dbc6c752d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ff0e80b7562e4ad6998f057b76c18306",
            "placeholder": "​",
            "style": "IPY_MODEL_3c1787f42aeb4daa9e0d8cc26ec29232",
            "value": "Map: 100%"
          }
        },
        "6966a83400484080ab10c8e871a27fbf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c5f2329886b1417bbf8f90995c2ae184",
            "max": 50,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b3a7907361094975b46df01148a7cbe8",
            "value": 50
          }
        },
        "b0f82745646e4d5db681e68e73442796": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ce5ff7facd6b4c16a12c187794996c34",
            "placeholder": "​",
            "style": "IPY_MODEL_481607876a424527af20d90102eeccfb",
            "value": " 50/50 [00:00&lt;00:00, 497.66 examples/s]"
          }
        },
        "227c873e3a4c4f3c8e3a51a4c745a27b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff0e80b7562e4ad6998f057b76c18306": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c1787f42aeb4daa9e0d8cc26ec29232": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c5f2329886b1417bbf8f90995c2ae184": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b3a7907361094975b46df01148a7cbe8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ce5ff7facd6b4c16a12c187794996c34": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "481607876a424527af20d90102eeccfb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "de2c543fe5fb4b98b24b0a07ab47bf6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8904a31eb345477ebd2667d03aeab3d3",
              "IPY_MODEL_5fa76fa8e763463a9acfe3381955e0b8",
              "IPY_MODEL_c5ac7e63227943a0822c9e51cb20a1ce"
            ],
            "layout": "IPY_MODEL_cdc18f4c00914c14a0c94e0bff72d485"
          }
        },
        "8904a31eb345477ebd2667d03aeab3d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_319e7c701a9b46798707f603a2ac059c",
            "placeholder": "​",
            "style": "IPY_MODEL_ed145df254014541af2161f6355088c2",
            "value": "Map: 100%"
          }
        },
        "5fa76fa8e763463a9acfe3381955e0b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_69eb4252c8d245f4b2ae455c69d9e227",
            "max": 50,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8ebffa6a4d504c8fa90c07f4faeb5d6e",
            "value": 50
          }
        },
        "c5ac7e63227943a0822c9e51cb20a1ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_97ae903ad4884b0c971ac2ceb5c2dbb9",
            "placeholder": "​",
            "style": "IPY_MODEL_d26b09b573d940bbabc4c406da71bee9",
            "value": " 50/50 [00:00&lt;00:00, 495.32 examples/s]"
          }
        },
        "cdc18f4c00914c14a0c94e0bff72d485": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "319e7c701a9b46798707f603a2ac059c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed145df254014541af2161f6355088c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "69eb4252c8d245f4b2ae455c69d9e227": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ebffa6a4d504c8fa90c07f4faeb5d6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "97ae903ad4884b0c971ac2ceb5c2dbb9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d26b09b573d940bbabc4c406da71bee9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7608d6892f584a14a93ac98dc748854e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f12644b58cc94429b80552de2bcceab5",
              "IPY_MODEL_f9469c06f54c4fa6b330fd1c6a6d441f",
              "IPY_MODEL_f788dd49a98a42439ff7082a5b567e4b"
            ],
            "layout": "IPY_MODEL_c25690253f1f4a08a488ef7759c1bccf"
          }
        },
        "f12644b58cc94429b80552de2bcceab5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_68bcd177192243d589bd22abdd031675",
            "placeholder": "​",
            "style": "IPY_MODEL_9a016ee934eb4fc7af8eb8d9c48fc5c0",
            "value": "Truncating train dataset (num_proc=4): 100%"
          }
        },
        "f9469c06f54c4fa6b330fd1c6a6d441f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b28e311d77b479c81e70d7f1465da74",
            "max": 50,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_69601374e5e34fa2bbc5fc1009e6a40a",
            "value": 50
          }
        },
        "f788dd49a98a42439ff7082a5b567e4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4fb3c057aa5c45afaa7ff58978e16617",
            "placeholder": "​",
            "style": "IPY_MODEL_8bbd5e6dac1f485cbaccbbd41dc1a379",
            "value": " 50/50 [00:00&lt;00:00, 99.39 examples/s]"
          }
        },
        "c25690253f1f4a08a488ef7759c1bccf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68bcd177192243d589bd22abdd031675": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a016ee934eb4fc7af8eb8d9c48fc5c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7b28e311d77b479c81e70d7f1465da74": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "69601374e5e34fa2bbc5fc1009e6a40a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4fb3c057aa5c45afaa7ff58978e16617": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8bbd5e6dac1f485cbaccbbd41dc1a379": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a1be8fffe07b452081162eda6b2a544d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c7251927e1484558afc151ca24794f42",
              "IPY_MODEL_ebf2013a65874f78969bcc163e175e2c",
              "IPY_MODEL_b52e3b945aec46f68941fa58f1b640c2"
            ],
            "layout": "IPY_MODEL_af840eaba5e842ea8342575bb090733a"
          }
        },
        "c7251927e1484558afc151ca24794f42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_920880dc22e24cd081eadace045426bf",
            "placeholder": "​",
            "style": "IPY_MODEL_84f110f3939047f9b1fcc42556f3b254",
            "value": "Truncating eval dataset (num_proc=4): 100%"
          }
        },
        "ebf2013a65874f78969bcc163e175e2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_78e477d5d5a747b2a29fea4a13450633",
            "max": 50,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_38cec7194c184047b36c26008036f08f",
            "value": 50
          }
        },
        "b52e3b945aec46f68941fa58f1b640c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e4074108bd5d4519937b9bfe1993726f",
            "placeholder": "​",
            "style": "IPY_MODEL_88338f67d73748b1a788af7bb9bf68fd",
            "value": " 50/50 [00:00&lt;00:00, 92.12 examples/s]"
          }
        },
        "af840eaba5e842ea8342575bb090733a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "920880dc22e24cd081eadace045426bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "84f110f3939047f9b1fcc42556f3b254": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "78e477d5d5a747b2a29fea4a13450633": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "38cec7194c184047b36c26008036f08f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e4074108bd5d4519937b9bfe1993726f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "88338f67d73748b1a788af7bb9bf68fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gyasifred/nutrikids-ai/blob/main/non_instruction_finetuning_peft.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook, I will fine-tune `unsloth/Llama-3.2-1B-Instruct-bnb-4bit` (non-instruction) using LoRA, a parameter-efficient fine-tuning method, to detect `Pediatric Malnutrition` from clinical notes."
      ],
      "metadata": {
        "id": "vyNmqkbfuBlB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "QXUP6s00t7Af"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "import os\n",
        "if \"COLAB_\" not in \"\".join(os.environ.keys()):\n",
        "    !pip install unsloth\n",
        "else:\n",
        "    # Do this only in Colab notebooks! Otherwise use pip install unsloth\n",
        "    !pip install --no-deps bitsandbytes accelerate xformers==0.0.29.post3 peft trl triton cut_cross_entropy unsloth_zoo\n",
        "    !pip install sentencepiece protobuf datasets huggingface_hub hf_transfer\n",
        "    !pip install --no-deps unsloth"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1HEAkuDI2AZE",
        "outputId": "2a170bab-d8e6-491e-fa7d-da4811fac281"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.12.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.14)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.29.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.2.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Begin with utility functions to process dataset\n"
      ],
      "metadata": {
        "id": "33YW5cdSvsrI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile utils.py\n",
        "\n",
        "from typing import List, Dict, Optional, Any\n",
        "import pandas as pd\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import os\n",
        "\n",
        "class MalnutritionDataset:\n",
        "    \"\"\"Class to handle malnutrition dataset operations.\"\"\"\n",
        "\n",
        "    def __init__(self, data_path: str, note_col: str, label_col: str):\n",
        "        \"\"\"Initialize dataset from a CSV file.\n",
        "\n",
        "        Args:\n",
        "            data_path (str): Path to the CSV file containing the data\n",
        "            note_col (str): Name of the text column in the CSV\n",
        "            label_col (str): Name of the label column in the CSV\n",
        "        \"\"\"\n",
        "        self.df = pd.read_csv(data_path)\n",
        "        self.text = note_col\n",
        "        self.label = label_col\n",
        "\n",
        "    def prepare_training_data(self) -> List[Dict[str, str]]:\n",
        "        \"\"\"Prepare data in the format required for training.\n",
        "\n",
        "        Args:\n",
        "            None\n",
        "\n",
        "        Returns:\n",
        "            List of dictionaries with text and labels formatted for training\n",
        "        \"\"\"\n",
        "        formatted_data = []\n",
        "        for _, row in self.df.iterrows():\n",
        "            # Generate prompt for each example\n",
        "            note = row[self.text]\n",
        "\n",
        "            formatted_data.append({\n",
        "                \"text\": note,\n",
        "                \"labels\": \"yes\" if str(row[self.label]).lower() in [\"1\", \"yes\", \"true\"] else \"no\"\n",
        "            })\n",
        "\n",
        "        return formatted_data\n",
        "\n",
        "def set_seed(seed: int = 42):\n",
        "    \"\"\"Set random seed for reproducibility.\n",
        "\n",
        "    Args:\n",
        "        seed (int): Random seed value\n",
        "    \"\"\"\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "\n",
        "\n",
        "def is_bfloat16_supported():\n",
        "    \"\"\"Check if bfloat16 is supported by the current device.\n",
        "\n",
        "    Returns:\n",
        "        bool: True if bfloat16 is supported, False otherwise\n",
        "    \"\"\"\n",
        "    return torch.cuda.is_available() and torch.cuda.get_device_capability()[0] >= 8"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r0ozBDelv_qO",
        "outputId": "cc0c0bbd-a3e5-4b56-8abb-f11da34456db"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing utils.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile train.csv\n",
        "DEID,txt,label\n",
        "1001,\"5-year-old male presents with persistent weight loss over the past 6 months. Parents report decreased appetite and fatigue. BMI below 5th percentile. Noted muscle wasting and thin hair. Plan: Nutrition consult, CBC, and metabolic panel.\",1\n",
        "1002,\"8-year-old female seen for routine well-child visit. No concerns reported. Weight and height within normal range for age. No history of feeding difficulties. Diet includes a variety of fruits, vegetables, and proteins.\",0\n",
        "1003,\"3-year-old male with history of premature birth presents with failure to gain weight. Mother reports frequent diarrhea and poor appetite. Weight-for-age below expected. Plan: Nutritional supplementation and gastroenterology referral.\",1\n",
        "1004,\"10-year-old female with no significant medical history. Growth chart shows consistent progression along the 50th percentile. No concerns for malnutrition. Active and well-nourished per caregiver report.\",0\n",
        "1005,\"6-year-old male with recurrent hospitalizations for pneumonia. Noted to be underweight for age with visible rib prominence. Parents report limited food intake due to poor appetite. Plan: High-calorie diet and vitamin supplementation.\",1\n",
        "1006,\"7-year-old female with no acute complaints. Normal weight and height progression. Balanced diet per family report. No signs of malnutrition on exam.\",0\n",
        "1007,\"2-year-old male with history of chronic diarrhea and weight stagnation. Physical exam reveals thin extremities and mild edema. Laboratory findings suggest micronutrient deficiencies. Referred to pediatric nutritionist.\",1\n",
        "1008,\"4-year-old female here for routine check-up. No concerns from parents. Growth chart remains stable at 60th percentile. No history of feeding issues.\",0\n",
        "1009,\"9-year-old male with history of cystic fibrosis. Reports decreased appetite and weight loss over past 3 months. BMI below 3rd percentile. Plan: Increase caloric intake and assess pancreatic enzyme supplementation.\",1\n",
        "1010,\"11-year-old female with no history of chronic illness. Reports regular physical activity and a well-balanced diet. Weight and height appropriate for age.\",0\n",
        "1011,\"18-month-old male with failure to thrive. Parents report limited intake of solid foods, frequent irritability, and delayed developmental milestones. Exam reveals mild muscle wasting and abdominal distension.\",1\n",
        "1012,\"5-year-old female with no concerns. Good appetite reported. Physical exam normal. Weight and height tracking along expected percentiles.\",0\n",
        "1013,\"4-year-old male with history of congenital heart disease. Reports poor weight gain despite high-calorie formula. Thin extremities noted. Plan: Referral to cardiology and nutrition team.\",1\n",
        "1014,\"6-year-old female with normal weight progression. No reported feeding difficulties. Parents report diverse diet and adequate intake.\",0\n",
        "1015,\"3-year-old female with chronic malnutrition, stunted growth, and low muscle tone. History of recurrent infections and poor dietary intake. Plan: Multidisciplinary intervention.\",1\n",
        "1016,\"12-year-old male with no history of weight or nutritional concerns. Active in sports and maintains healthy diet. Growth consistent with expected pattern.\",0\n",
        "1017,\"5-year-old female with history of neglect, presenting with severe malnutrition. Exam shows wasting, dry skin, and brittle hair. Plan: Hospital admission for nutritional rehabilitation.\",1\n",
        "1018,\"7-year-old male with no significant medical history. Reports normal appetite and energy levels. Growth chart stable.\",0\n",
        "1019,\"10-month-old infant with significant weight faltering. Parents report difficulty with feeding and frequent vomiting. Noted to be below the 3rd percentile for weight. Referral to gastroenterology and dietitian made.\",1\n",
        "1020,\"8-year-old female with no concerns regarding nutrition. Normal development, active lifestyle, and well-balanced diet reported.\",0\n",
        "1021,\"2-year-old male with chronic undernutrition. Noted to have delayed milestones and reduced muscle mass. Parents report financial difficulties impacting food availability.\",1\n",
        "1022,\"5-year-old female thriving with adequate caloric intake. Growth curve follows 70th percentile. No signs of malnutrition.\",0\n",
        "1023,\"9-year-old male presents with persistent fatigue and poor growth. Weight below 5th percentile. Exam shows signs of micronutrient deficiencies. Plan: Dietary interventions and lab work-up.\",1\n",
        "1024,\"6-year-old female with normal appetite and growth. No medical history of malnutrition or weight concerns.\",0\n",
        "1025,\"11-month-old male with severe malnutrition and irritability. Weight-for-length below expected. Signs of rickets noted. Hospital admission recommended.\",1\n",
        "1026,\"4-year-old female with no weight or nutrition concerns. Active and meeting developmental milestones. No abnormalities noted on exam.\",0\n",
        "1027,\"2-year-old male with history of low birth weight. Struggles with weight gain despite formula supplementation. Plan: Further dietary evaluation.\",1\n",
        "1028,\"7-year-old female with no medical concerns. Growth follows 50th percentile. Regular diet with no feeding issues reported.\",0\n",
        "1029,\"8-month-old infant with significant weight loss. Parents report difficulty introducing solid foods. Noted to have thin arms and legs with reduced fat stores. Plan: Close follow-up with pediatrician and dietitian.\",1\n",
        "1030,\"10-year-old male seen for sports physical. No concerns reported. Active and well-nourished with normal growth.\",0\n",
        "1031,\"4-year-old female with recent hospitalization for severe malnutrition. Presented with muscle wasting and lethargy. Now on high-calorie diet and improving.\",1\n",
        "1032,\"6-year-old male with normal appetite. Parents report balanced diet. No growth concerns.\",0\n",
        "1033,\"18-month-old male with kwashiorkor-like symptoms, including edema and skin changes. History of protein-deficient diet. Plan: Urgent nutritional intervention.\",1\n",
        "1034,\"5-year-old female seen for check-up. No nutritional concerns. Growth curve steady.\",0\n",
        "1035,\"3-year-old male with history of recurrent infections and poor weight gain. Physical exam reveals prominent ribs and thinning hair. Plan: Nutritional and immunology evaluation.\",1\n",
        "1036,\"12-year-old female reports good appetite and physical activity. Normal weight and height for age. No concerns noted.\",0\n",
        "1037,\"9-month-old male with severe undernutrition. Weight-for-age below 1st percentile. Signs of developmental delay. Plan: Hospitalization for nutritional support.\",1\n",
        "1038,\"7-year-old male with no history of dietary concerns. Regular meals, adequate weight gain, and normal growth.\",0\n",
        "1039,\"5-year-old male presents with stunted growth. Parents report selective eating habits and poor weight gain. Plan: Nutritional counseling.\",1\n",
        "1040,\"10-year-old female with healthy dietary habits. No signs of malnutrition. Growth tracking within normal range.\",0\n",
        "1041,\"2-year-old male with chronic undernutrition and vitamin deficiencies. Parents report difficulty affording nutritious food. Plan: Social services referral.\",1\n",
        "1042,\"6-year-old female with no reported concerns. Eating well and maintaining weight. Growth chart normal.\",0\n",
        "1043,\"3-year-old male with visible signs of wasting. Mother reports inadequate food intake due to ongoing illness. Plan: Nutritional rehabilitation and medical work-up.\",1\n",
        "1044,\"11-year-old female reports regular eating habits and no health concerns. No weight loss or nutritional deficiencies noted.\",0\n",
        "1045,\"8-month-old female with severe weight loss and lethargy. Physical exam concerning for malnutrition. Admitted for nutritional support.\",1\n",
        "1046,\"9-year-old male with no issues related to nutrition. Growing appropriately and active in sports.\",0\n",
        "1047,\"14-month-old female with moderate acute malnutrition. Weight-for-age below 3rd percentile. Plan: Nutritional supplementation.\",1\n",
        "1048,\"7-year-old male seen for well-child visit. No signs of undernutrition. Weight stable at 55th percentile.\",0\n",
        "1049,\"2-year-old male with history of recurrent illness and weight faltering. Exam shows thin extremities and delayed growth. Plan: Dietary assessment and follow-up.\",1\n",
        "1050,\"6-year-old female eating a varied diet with no signs of malnutrition. Normal growth and development noted.\",0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Um864Z6_xXGJ",
        "outputId": "16dac607-bbe6-460f-a0c3-8cf81bd9eefa"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing train.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile valid.csv\n",
        "DEID,txt,label\n",
        "1051,\"3-year-old female presents with poor weight gain. Parents report frequent vomiting and refusal to eat solid foods. BMI below 3rd percentile. Plan: Dietitian referral and GI workup.\",1\n",
        "1052,\"7-year-old male seen for annual check-up. No feeding issues reported. Growth chart stable at 60th percentile. No concerns for malnutrition.\",0\n",
        "1053,\"5-year-old male with history of congenital heart defect. Struggling with weight gain despite fortified diet. Mild muscle wasting noted. Plan: High-calorie dietary modifications.\",1\n",
        "1054,\"10-year-old female with no medical concerns. Growth parameters within expected range. Well-balanced diet reported by parents.\",0\n",
        "1055,\"2-year-old male with chronic diarrhea and failure to thrive. Weight below expected for age. Exam reveals thin extremities and dry skin. Plan: Nutrition and GI consult.\",1\n",
        "1056,\"8-year-old female with no significant weight changes. Normal dietary intake reported. No signs of nutritional deficiencies.\",0\n",
        "1057,\"4-year-old male with severe malnutrition, presenting with fatigue and stunted growth. Parents report limited access to food. Plan: Multidisciplinary intervention.\",1\n",
        "1058,\"6-year-old female with no medical concerns. Healthy eating habits and appropriate weight for age. No nutritional deficiencies observed.\",0\n",
        "1059,\"9-month-old male with difficulty gaining weight. Parents report poor appetite and recurrent infections. Growth chart shows weight-for-age below 1st percentile.\",1\n",
        "1060,\"12-year-old female with stable growth along the 50th percentile. No feeding issues or concerns reported.\",0\n",
        "1061,\"18-month-old male with severe weight loss and lethargy. Parents report difficulty introducing solid foods. Noted to be below the 3rd percentile for weight. Plan: Hospital admission for nutritional support.\",1\n",
        "1062,\"5-year-old female with normal weight progression. Parents report good appetite. No concerns for malnutrition.\",0\n",
        "1063,\"6-year-old male with recurrent hospitalizations for pneumonia. Noted to be underweight for age with visible rib prominence. Parents report limited food intake due to poor appetite. Plan: High-calorie diet and vitamin supplementation.\",1\n",
        "1064,\"8-year-old male with no history of chronic illness. Reports regular physical activity and a well-balanced diet. Weight and height appropriate for age.\",0\n",
        "1065,\"3-year-old female with chronic malnutrition, stunted growth, and low muscle tone. History of recurrent infections and poor dietary intake. Plan: Multidisciplinary intervention.\",1\n",
        "1066,\"12-year-old male with no history of weight or nutritional concerns. Active in sports and maintains healthy diet. Growth consistent with expected pattern.\",0\n",
        "1067,\"5-year-old female with history of neglect, presenting with severe malnutrition. Exam shows wasting, dry skin, and brittle hair. Plan: Hospital admission for nutritional rehabilitation.\",1\n",
        "1068,\"7-year-old male with no significant medical history. Reports normal appetite and energy levels. Growth chart stable.\",0\n",
        "1069,\"10-month-old infant with significant weight faltering. Parents report difficulty with feeding and frequent vomiting. Noted to be below the 3rd percentile for weight. Referral to gastroenterology and dietitian made.\",1\n",
        "1070,\"8-year-old female with no concerns regarding nutrition. Normal development, active lifestyle, and well-balanced diet reported.\",0\n",
        "1071,\"2-year-old male with chronic undernutrition. Noted to have delayed milestones and reduced muscle mass. Parents report financial difficulties impacting food availability.\",1\n",
        "1072,\"5-year-old female thriving with adequate caloric intake. Growth curve follows 70th percentile. No signs of malnutrition.\",0\n",
        "1073,\"9-year-old male presents with persistent fatigue and poor growth. Weight below 5th percentile. Exam shows signs of micronutrient deficiencies. Plan: Dietary interventions and lab work-up.\",1\n",
        "1074,\"6-year-old female with normal appetite and growth. No medical history of malnutrition or weight concerns.\",0\n",
        "1075,\"11-month-old male with severe malnutrition and irritability. Weight-for-length below expected. Signs of rickets noted. Hospital admission recommended.\",1\n",
        "1076,\"4-year-old female with no weight or nutrition concerns. Active and meeting developmental milestones. No abnormalities noted on exam.\",0\n",
        "1077,\"2-year-old male with history of low birth weight. Struggles with weight gain despite formula supplementation. Plan: Further dietary evaluation.\",1\n",
        "1078,\"7-year-old female with no medical concerns. Growth follows 50th percentile. Regular diet with no feeding issues reported.\",0\n",
        "1079,\"8-month-old infant with significant weight loss. Parents report difficulty introducing solid foods. Noted to have thin arms and legs with reduced fat stores. Plan: Close follow-up with pediatrician and dietitian.\",1\n",
        "1080,\"10-year-old male seen for sports physical. No concerns reported. Active and well-nourished with normal growth.\",0\n",
        "1081,\"4-year-old female with recent hospitalization for severe malnutrition. Presented with muscle wasting and lethargy. Now on high-calorie diet and improving.\",1\n",
        "1082,\"6-year-old male with normal appetite. Parents report balanced diet. No growth concerns.\",0\n",
        "1083,\"18-month-old male with kwashiorkor-like symptoms, including edema and skin changes. History of protein-deficient diet. Plan: Urgent nutritional intervention.\",1\n",
        "1084,\"5-year-old female seen for check-up. No nutritional concerns. Growth curve steady.\",0\n",
        "1085,\"3-year-old male with history of recurrent infections and poor weight gain. Physical exam reveals prominent ribs and thinning hair. Plan: Nutritional and immunology evaluation.\",1\n",
        "1086,\"12-year-old female reports good appetite and physical activity. Normal weight and height for age. No concerns noted.\",0\n",
        "1087,\"9-month-old male with severe undernutrition. Weight-for-age below 1st percentile. Signs of developmental delay. Plan: Hospitalization for nutritional support.\",1\n",
        "1088,\"7-year-old male with no history of dietary concerns. Regular meals, adequate weight gain, and normal growth.\",0\n",
        "1089,\"5-year-old male presents with stunted growth. Parents report selective eating habits and poor weight gain. Plan: Nutritional counseling.\",1\n",
        "1090,\"10-year-old female with healthy dietary habits. No signs of malnutrition. Growth tracking within normal range.\",0\n",
        "1091,\"2-year-old male with chronic undernutrition and vitamin deficiencies. Parents report difficulty affording nutritious food. Plan: Social services referral.\",1\n",
        "1092,\"6-year-old female with no reported concerns. Eating well and maintaining weight. Growth chart normal.\",0\n",
        "1093,\"3-year-old male with visible signs of wasting. Mother reports inadequate food intake due to ongoing illness. Plan: Nutritional rehabilitation and medical work-up.\",1\n",
        "1094,\"11-year-old female reports regular eating habits and no health concerns. No weight loss or nutritional deficiencies noted.\",0\n",
        "1095,\"8-month-old female with severe weight loss and lethargy. Physical exam concerning for malnutrition. Admitted for nutritional support.\",1\n",
        "1096,\"9-year-old male with no issues related to nutrition. Growing appropriately and active in sports.\",0\n",
        "1097,\"14-month-old female with moderate acute malnutrition. Weight-for-age below 3rd percentile. Plan: Nutritional supplementation.\",1\n",
        "1098,\"7-year-old male seen for well-child visit. No signs of undernutrition. Weight stable at 55th percentile.\",0\n",
        "1099,\"2-year-old male with history of recurrent illness and weight faltering. Exam shows thin extremities and delayed growth. Plan: Dietary assessment and follow-up.\",1\n",
        "1100,\"6-year-old female eating a varied diet with no signs of malnutrition. Normal growth and development noted.\",0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9H7nKXSClBe",
        "outputId": "d8e9c177-896e-452c-f103-e67b70b3b065"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing valid.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check out our dataset"
      ],
      "metadata": {
        "id": "TzVQkfsYzTxw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from utils import MalnutritionDataset\n",
        "\n",
        "malnutrition_dataset = MalnutritionDataset(\n",
        "    data_path=\"train.csv\",\n",
        "    note_col=\"txt\",\n",
        "    label_col=\"label\"\n",
        ")\n",
        "train_data = malnutrition_dataset.prepare_training_data()"
      ],
      "metadata": {
        "id": "j_97Oe0TzbYV"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data[:2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dIRWfOY30vDU",
        "outputId": "ae5be4f9-c1f4-43d7-ccb6-3ad9c4d00cc9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'text': '5-year-old male presents with persistent weight loss over the past 6 months. Parents report decreased appetite and fatigue. BMI below 5th percentile. Noted muscle wasting and thin hair. Plan: Nutrition consult, CBC, and metabolic panel.',\n",
              "  'labels': 'yes'},\n",
              " {'text': '8-year-old female seen for routine well-child visit. No concerns reported. Weight and height within normal range for age. No history of feeding difficulties. Diet includes a variety of fruits, vegetables, and proteins.',\n",
              "  'labels': 'no'}]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from datasets import Dataset\n",
        "from transformers import BitsAndBytesConfig\n",
        "from trl import SFTTrainer, SFTConfig\n",
        "from unsloth import FastLanguageModel\n",
        "import pandas as pd\n",
        "import json\n",
        "from utils import (\n",
        "    MalnutritionDataset,\n",
        "    is_bfloat16_supported,\n",
        "    set_seed\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WKd5VQcm09Ab",
        "outputId": "42aa3189-748d-4395-9fc9-0f16f8266c91"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-f11512cea90a>:5: UserWarning: WARNING: Unsloth should be imported before trl, transformers, peft to ensure all optimizations are applied. Your code may run slower or encounter memory issues without these optimizations.\n",
            "\n",
            "Please restructure your imports with 'import unsloth' at the top of your file.\n",
            "  from unsloth import FastLanguageModel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
            "🦥 Unsloth Zoo will now patch everything to make training faster!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_quantization_config(config):\n",
        "    \"\"\"Define quantization configuration for the model based on arguments.\n",
        "\n",
        "    Args:\n",
        "        args: Command line arguments\n",
        "\n",
        "    Returns:\n",
        "        BitsAndBytesConfig: Quantization configuration\n",
        "    \"\"\"\n",
        "    # Determine if we should use 8-bit or 4-bit quantization (but not both)\n",
        "    if config['load_in_8bit']:\n",
        "        return BitsAndBytesConfig(\n",
        "            load_in_8bit=True,\n",
        "            load_in_4bit=False,\n",
        "            llm_int8_enable_fp32_cpu_offload=True\n",
        "        )\n",
        "    elif config['load_in_4bit']:\n",
        "        # Determine compute dtype based on available hardware and args\n",
        "        if config['force_bf16'] and is_bfloat16_supported():\n",
        "            compute_dtype = torch.bfloat16\n",
        "        else:\n",
        "            compute_dtype = torch.float16\n",
        "\n",
        "        return BitsAndBytesConfig(\n",
        "            load_in_4bit=True,\n",
        "            load_in_8bit=False,\n",
        "            bnb_4bit_compute_dtype=compute_dtype,\n",
        "            bnb_4bit_quant_type=\"nf4\",\n",
        "            bnb_4bit_use_double_quant=True,\n",
        "            llm_int8_enable_fp32_cpu_offload=True,\n",
        "            llm_int8_threshold=6.0,\n",
        "            llm_int8_has_fp16_weight=True\n",
        "        )\n",
        "    else:\n",
        "        # No quantization\n",
        "        return None\n",
        "\n",
        "\n",
        "def determine_model_precision(config):\n",
        "    \"\"\"Determine appropriate precision settings for model training.\n",
        "\n",
        "    Args:\n",
        "        args: Command line arguments\n",
        "\n",
        "    Returns:\n",
        "        tuple: (fp16, bf16) boolean flags\n",
        "    \"\"\"\n",
        "    if config['force_fp16']:\n",
        "        return True, False\n",
        "\n",
        "    if config['force_bf16']:\n",
        "        if is_bfloat16_supported():\n",
        "            return False, True\n",
        "        else:\n",
        "            print(\"Warning: BF16 requested but not supported by hardware. Falling back to FP16.\")\n",
        "            return True, False\n",
        "\n",
        "    # Auto-detect best precision\n",
        "    if is_bfloat16_supported():\n",
        "        return False, True\n",
        "    else:\n",
        "        return True, False\n",
        "\n",
        "\n",
        "def load_model_and_tokenizer(config, quantization_config):\n",
        "    \"\"\"Load base model and tokenizer with appropriate settings.\"\"\"\n",
        "    print(f\"Loading base model and tokenizer: {config['model_name']}\")\n",
        "\n",
        "    # Determine precision based on hardware and user preferences\n",
        "    fp16, bf16 = determine_model_precision(config)\n",
        "    dtype = torch.bfloat16 if bf16 else torch.float16\n",
        "\n",
        "    try:\n",
        "        # Ensure we're not using both 4-bit and 8-bit\n",
        "        load_in_4bit = config['load_in_4bit'] and not config['load_in_8bit']\n",
        "        load_in_8bit = config['load_in_8bit'] and not config['load_in_4bit']\n",
        "\n",
        "        print(f\"Loading model with settings: precision={'bf16' if bf16 else 'fp16'}, \"\n",
        "              f\"load_in_4bit={load_in_4bit}, load_in_8bit={load_in_8bit}\")\n",
        "\n",
        "        # Set attention implementation based on flash attention flag\n",
        "        attn_implementation = \"flash_attention_2\" if config['use_flash_attention'] else \"eager\"\n",
        "\n",
        "        # Create kwargs for model loading\n",
        "        model_kwargs = {\n",
        "            \"model_name\": config['model_name'],\n",
        "            \"dtype\": dtype,\n",
        "            \"device_map\": \"auto\",\n",
        "            \"attn_implementation\": attn_implementation,\n",
        "        }\n",
        "\n",
        "        # If quantization_config is provided, use it\n",
        "        if quantization_config is not None:\n",
        "            model_kwargs[\"quantization_config\"] = quantization_config\n",
        "        else:\n",
        "            # Otherwise use the direct parameters\n",
        "            model_kwargs[\"load_in_4bit\"] = load_in_4bit\n",
        "            model_kwargs[\"load_in_8bit\"] = load_in_8bit\n",
        "\n",
        "        # Load the model with the appropriate parameters\n",
        "        base_model, tokenizer = FastLanguageModel.from_pretrained(**model_kwargs)\n",
        "\n",
        "        print(\"Model and tokenizer loaded successfully.\")\n",
        "        return base_model, tokenizer, fp16, bf16\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading model: {e}\")\n",
        "        raise\n",
        "\n",
        "\n",
        "def get_target_modules(args, model_name):\n",
        "    \"\"\"Determine appropriate target modules for LoRA based on model architecture.\n",
        "\n",
        "    Args:\n",
        "        args: Command line arguments\n",
        "        model_name: Name of the model\n",
        "\n",
        "    Returns:\n",
        "        list: List of target module names\n",
        "    \"\"\"\n",
        "    # If user specified target modules, use those\n",
        "    if args['target_modules']:\n",
        "        return args['target_modules'].split(',')\n",
        "\n",
        "    # Default target modules based on model architecture\n",
        "    model_name_lower = model_name.lower()\n",
        "\n",
        "    if any(name in model_name_lower for name in [\"llama\", \"mistral\", \"mixtral\"]):\n",
        "        return [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"]\n",
        "    elif \"phi\" in model_name_lower:\n",
        "        return [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"]\n",
        "    elif \"qwen\" in model_name_lower:\n",
        "        return [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"w1\", \"w2\"]\n",
        "    elif \"deepseek\" in model_name_lower:\n",
        "        return [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"]\n",
        "\n",
        "    # Default fallback\n",
        "    return [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"]"
      ],
      "metadata": {
        "id": "pj2fdiaY22hP"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_peft_model(base_model, config):\n",
        "    \"\"\"Create PEFT/LoRA model for fine-tuning with appropriate settings.\n",
        "\n",
        "    Args:\n",
        "        base_model: The base language model\n",
        "        args: Command line arguments\n",
        "\n",
        "    Returns:\n",
        "        model: The PEFT model ready for training\n",
        "    \"\"\"\n",
        "    print(\"Creating PEFT/LoRA model...\")\n",
        "\n",
        "    # Get appropriate target modules for this model architecture\n",
        "    target_modules = get_target_modules(config, config['model_name'])\n",
        "    print(f\"Using target modules: {target_modules}\")\n",
        "\n",
        "    model = FastLanguageModel.get_peft_model(\n",
        "        model=base_model,\n",
        "        r=config['lora_r'],\n",
        "        lora_alpha=config['lora_alpha'],\n",
        "        lora_dropout=0,\n",
        "        target_modules=target_modules,\n",
        "        use_gradient_checkpointing=True,\n",
        "        random_state=config['seed'],\n",
        "        use_rslora=True,\n",
        "        loftq_config=None\n",
        "    )\n",
        "\n",
        "    # Enable gradient checkpointing for efficient training\n",
        "    model.gradient_checkpointing_enable()\n",
        "    if hasattr(model, 'enable_input_require_grads'):\n",
        "        model.enable_input_require_grads()\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def get_sft_config(config, fp16, bf16):\n",
        "    \"\"\"Configure SFT training arguments.\n",
        "\n",
        "    Args:\n",
        "        args: Command line arguments\n",
        "        fp16: Whether to use FP16 precision\n",
        "        bf16: Whether to use BF16 precision\n",
        "\n",
        "    Returns:\n",
        "        SFTConfig: Configuration for SFT training\n",
        "    \"\"\"\n",
        "    config_kwargs = {\n",
        "        \"per_device_train_batch_size\": config['batch_size'],\n",
        "        \"gradient_accumulation_steps\": config['gradient_accumulation'],\n",
        "        \"warmup_steps\": 5,\n",
        "        # \"max_steps\": args.max_steps,\n",
        "        \"learning_rate\": config['learning_rate'],\n",
        "        \"fp16\": fp16,\n",
        "        \"bf16\": bf16,\n",
        "        \"logging_steps\": 1,\n",
        "        \"optim\": \"adamw_8bit\",\n",
        "        \"weight_decay\": 0.01,\n",
        "        \"lr_scheduler_type\": \"linear\",\n",
        "        \"seed\": config['seed'],\n",
        "        \"output_dir\": config['output_dir'],\n",
        "        \"report_to\": config['report_to'],\n",
        "        \"save_strategy\": \"steps\",\n",
        "        \"save_steps\": 10,\n",
        "        \"max_seq_length\": config['max_seq_length'],\n",
        "        \"dataset_num_proc\": 4,\n",
        "        \"packing\": False,\n",
        "        \"num_train_epochs\": config['epochs']\n",
        "    }\n",
        "\n",
        "    # Add evaluation parameters only if validation data is provided\n",
        "    if config['val_data'] is not None:\n",
        "        config_kwargs.update({\n",
        "            \"eval_strategy\": \"steps\",\n",
        "            \"eval_steps\": 10,\n",
        "            \"load_best_model_at_end\": True,\n",
        "            \"metric_for_best_model\": \"eval_loss\",\n",
        "        })\n",
        "\n",
        "    print(f\"Training with precision: fp16={fp16}, bf16={bf16}\")\n",
        "    return SFTConfig(**config_kwargs)\n",
        "\n",
        "\n",
        "def prepare_datasets(train_data_path, val_data_path, tokenizer, note_col, label_col, max_seq_length):\n",
        "    \"\"\"Prepare training and validation datasets.\n",
        "\n",
        "    Args:\n",
        "        train_data_path (str): Path to training data CSV\n",
        "        val_data_path (str): Path to validation data CSV\n",
        "        prompt_builder: MalnutritionPromptBuilder instance\n",
        "        tokenizer: Tokenizer for the model\n",
        "        note_col (str): Name of the text column\n",
        "        label_col (str): Name of the label column\n",
        "        max_seq_length (int): Maximum sequence length for tokenization\n",
        "\n",
        "    Returns:\n",
        "        Tuple: (train_dataset, eval_dataset)\n",
        "    \"\"\"\n",
        "    print(\"Preparing datasets...\")\n",
        "\n",
        "    # Load and prepare training data\n",
        "    train_data = MalnutritionDataset(train_data_path, note_col, label_col)\n",
        "    train_formatted = train_data.prepare_training_data()\n",
        "\n",
        "    # Pre-tokenize the data to ensure consistent format\n",
        "    def tokenize_function(examples):\n",
        "        # Make sure 'text' field exists and is not empty\n",
        "        if not examples.get('text'):\n",
        "            return {\"input_ids\": [], \"attention_mask\": []}\n",
        "\n",
        "        # Tokenize the examples\n",
        "        tokenized = tokenizer(\n",
        "            examples['text'],\n",
        "            truncation=True,\n",
        "            padding=\"max_length\",\n",
        "            max_length=max_seq_length,\n",
        "            return_tensors=None,\n",
        "        )\n",
        "        # Add labels for supervised fine-tuning\n",
        "        tokenized[\"labels\"] = tokenized[\"input_ids\"].copy()\n",
        "        return tokenized\n",
        "\n",
        "    # Convert to Dataset and tokenize\n",
        "    train_dataset = Dataset.from_pandas(pd.DataFrame(train_formatted))\n",
        "    train_tokenized = train_dataset.map(\n",
        "        tokenize_function,\n",
        "        batched=False,\n",
        "        remove_columns=[\"text\"] if \"text\" in train_dataset.column_names else [],\n",
        "    )\n",
        "\n",
        "    # Handle validation data if provided\n",
        "    eval_tokenized = None\n",
        "    if val_data_path is not None:\n",
        "        val_data = MalnutritionDataset(val_data_path, note_col, label_col)\n",
        "        val_formatted = val_data.prepare_training_data()\n",
        "        eval_dataset = Dataset.from_pandas(pd.DataFrame(val_formatted))\n",
        "        eval_tokenized = eval_dataset.map(\n",
        "            tokenize_function,\n",
        "            batched=False,\n",
        "            remove_columns=[\"text\"] if \"text\" in eval_dataset.column_names else [],\n",
        "        )\n",
        "        print(f\"Prepared {len(train_tokenized)} training examples and {len(eval_tokenized)} validation examples\")\n",
        "    else:\n",
        "        print(f\"Prepared {len(train_tokenized)} training examples\")\n",
        "\n",
        "    return train_tokenized, eval_tokenized\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "config = {\n",
        "  \"model_name\": \"unsloth/Llama-3.2-1B-bnb-4bit\",\n",
        "  \"train_data\": \"/content/train.csv\",\n",
        "  \"val_data\":\"/content/valid.csv\",\n",
        "  \"text_column\": \"txt\",\n",
        "  \"label_column\": \"label\",\n",
        "  # Output arguments\n",
        "  \"output_dir\": \"./llm\",\n",
        "  \"model_output\": \"./llm_models\",\n",
        "\n",
        "  # Training arguments\n",
        "  \"batch_size\": 2,\n",
        "  \"gradient_accumulation\": 4,\n",
        "  \"learning_rate\": 2e-4,\n",
        "  \"max_seq_length\": 2048,\n",
        "  \"epochs\": 10,\n",
        "\n",
        "  # LoRA parameters\n",
        "  \"lora_r\": 8,\n",
        "  \"lora_alpha\": 32,\n",
        "  \"target_modules\": None,\n",
        "\n",
        "  # Precision arguments\n",
        "  \"force_fp16\": False,\n",
        "  \"force_bf16\": False,\n",
        "\n",
        "  # Miscellaneous\n",
        "  \"seed\": 42,\n",
        "  \"use_flash_attention\": False,\n",
        "  \"report_to\": \"none\",\n",
        "  \"load_in_8bit\": False,\n",
        "  \"load_in_4bit\": True\n",
        "}\n",
        "\n",
        "# Ensure mutual exclusivity of precision settings\n",
        "if config[\"load_in_8bit\"]:\n",
        "    config[\"load_in_4bit\"] = False\n",
        "\n",
        "# Set seed for reproducibility\n",
        "set_seed(config['seed'])\n",
        "\n",
        "# Create output directories\n",
        "os.makedirs(config['output_dir'], exist_ok=True)\n",
        "os.makedirs(config['model_output'], exist_ok=True)\n",
        "\n",
        "# Save configuration\n",
        "with open(os.path.join(config['output_dir'], \"config.json\"), \"w\") as f:\n",
        "    json.dump(config, f, indent=4)\n",
        "\n",
        "# Get quantization config\n",
        "quantization_config = get_quantization_config(config)\n",
        "\n",
        "# Load model and tokenizer with precision detection\n",
        "base_model, tokenizer, fp16, bf16 = load_model_and_tokenizer(\n",
        "    config, quantization_config\n",
        ")\n",
        "\n",
        "# Load and prepare datasets with tokenization\n",
        "train_dataset, eval_dataset = prepare_datasets(\n",
        "    config['train_data'],\n",
        "    config['val_data'],\n",
        "    tokenizer,\n",
        "    config['text_column'],\n",
        "    config['label_column'],\n",
        "    config['max_seq_length']\n",
        ")\n",
        "\n",
        "# Create PEFT/LoRA model\n",
        "model = create_peft_model(base_model, config)\n",
        "\n",
        "# Get SFT config with correct precision settings\n",
        "sft_config = get_sft_config(config, fp16, bf16)\n",
        "\n",
        "# Initialize SFT trainer\n",
        "trainer_kwargs = {\n",
        "    \"model\": model,\n",
        "    \"processing_class\": tokenizer,\n",
        "    \"train_dataset\": train_dataset,\n",
        "    \"args\": sft_config,\n",
        "}\n",
        "\n",
        "if eval_dataset is not None:\n",
        "    trainer_kwargs[\"eval_dataset\"] = eval_dataset\n",
        "\n",
        "trainer = SFTTrainer(**trainer_kwargs)\n",
        "\n",
        "import os\n",
        "os.environ['UNSLOTH_RETURN_LOGITS'] = '1'\n",
        "\n",
        "# Train the model\n",
        "print(f\"Starting training with {len(train_dataset)} examples for {config['epochs']} epoch(s)...\")\n",
        "trainer.train()\n",
        "\n",
        "# Save the final model\n",
        "print(f\"Training completed. Saving model to {config['model_output']}\")\n",
        "trainer.save_model(config['model_output'])\n",
        "\n",
        "print(\"Fine-tuning complete!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "b9f6c256c99c482fbaefdfe3be2cfd7f",
            "5bdb01c4383d46aebdaa221dbc6c752d",
            "6966a83400484080ab10c8e871a27fbf",
            "b0f82745646e4d5db681e68e73442796",
            "227c873e3a4c4f3c8e3a51a4c745a27b",
            "ff0e80b7562e4ad6998f057b76c18306",
            "3c1787f42aeb4daa9e0d8cc26ec29232",
            "c5f2329886b1417bbf8f90995c2ae184",
            "b3a7907361094975b46df01148a7cbe8",
            "ce5ff7facd6b4c16a12c187794996c34",
            "481607876a424527af20d90102eeccfb",
            "de2c543fe5fb4b98b24b0a07ab47bf6e",
            "8904a31eb345477ebd2667d03aeab3d3",
            "5fa76fa8e763463a9acfe3381955e0b8",
            "c5ac7e63227943a0822c9e51cb20a1ce",
            "cdc18f4c00914c14a0c94e0bff72d485",
            "319e7c701a9b46798707f603a2ac059c",
            "ed145df254014541af2161f6355088c2",
            "69eb4252c8d245f4b2ae455c69d9e227",
            "8ebffa6a4d504c8fa90c07f4faeb5d6e",
            "97ae903ad4884b0c971ac2ceb5c2dbb9",
            "d26b09b573d940bbabc4c406da71bee9",
            "7608d6892f584a14a93ac98dc748854e",
            "f12644b58cc94429b80552de2bcceab5",
            "f9469c06f54c4fa6b330fd1c6a6d441f",
            "f788dd49a98a42439ff7082a5b567e4b",
            "c25690253f1f4a08a488ef7759c1bccf",
            "68bcd177192243d589bd22abdd031675",
            "9a016ee934eb4fc7af8eb8d9c48fc5c0",
            "7b28e311d77b479c81e70d7f1465da74",
            "69601374e5e34fa2bbc5fc1009e6a40a",
            "4fb3c057aa5c45afaa7ff58978e16617",
            "8bbd5e6dac1f485cbaccbbd41dc1a379",
            "a1be8fffe07b452081162eda6b2a544d",
            "c7251927e1484558afc151ca24794f42",
            "ebf2013a65874f78969bcc163e175e2c",
            "b52e3b945aec46f68941fa58f1b640c2",
            "af840eaba5e842ea8342575bb090733a",
            "920880dc22e24cd081eadace045426bf",
            "84f110f3939047f9b1fcc42556f3b254",
            "78e477d5d5a747b2a29fea4a13450633",
            "38cec7194c184047b36c26008036f08f",
            "e4074108bd5d4519937b9bfe1993726f",
            "88338f67d73748b1a788af7bb9bf68fd"
          ]
        },
        "id": "HRRNsJyt3JES",
        "outputId": "585a49db-dcab-4bd7-a4e3-6bc773608bf5"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading base model and tokenizer: unsloth/Llama-3.2-1B-bnb-4bit\n",
            "Loading model with settings: precision=fp16, load_in_4bit=True, load_in_8bit=False\n",
            "==((====))==  Unsloth 2025.3.19: Fast Llama patching. Transformers: 4.50.0.\n",
            "   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.741 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 7.5. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
            "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.29.post3. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
            "Model and tokenizer loaded successfully.\n",
            "Preparing datasets...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/50 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b9f6c256c99c482fbaefdfe3be2cfd7f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/50 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "de2c543fe5fb4b98b24b0a07ab47bf6e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prepared 50 training examples and 50 validation examples\n",
            "Creating PEFT/LoRA model...\n",
            "Using target modules: ['q_proj', 'k_proj', 'v_proj', 'o_proj', 'gate_proj', 'up_proj', 'down_proj']\n",
            "Training with precision: fp16=True, bf16=False\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Truncating train dataset (num_proc=4):   0%|          | 0/50 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7608d6892f584a14a93ac98dc748854e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Truncating eval dataset (num_proc=4):   0%|          | 0/50 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a1be8fffe07b452081162eda6b2a544d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training with 50 examples for 10 epoch(s)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
            "   \\\\   /|    Num examples = 50 | Num Epochs = 10 | Total steps = 60\n",
            "O^O/ \\_/ \\    Batch size per device = 2 | Gradient accumulation steps = 4\n",
            "\\        /    Data Parallel GPUs = 1 | Total batch size (2 x 4 x 1) = 8\n",
            " \"-____-\"     Trainable parameters = 5,636,096/1,000,000,000 (0.56% trained)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unsloth: Will smartly offload gradients to save VRAM!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='11' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [11/60 00:58 < 05:16, 0.15 it/s, Epoch 1.48/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unsloth: Not an error, but LlamaForCausalLM does not accept `num_items_in_batch`.\n",
            "Using gradient accumulation will be very slightly less accurate.\n",
            "Read more on gradient accumulation issues here: https://unsloth.ai/blog/gradient\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 7.88 GiB. GPU 0 has a total capacity of 14.74 GiB of which 7.74 GiB is free. Process 11128 has 7.00 GiB memory in use. Of the allocated memory 6.82 GiB is allocated by PyTorch, and 26.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-f7f2463449ed>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Starting training with {len(train_dataset)} examples for {config['epochs']} epoch(s)...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[0;31m# Save the final model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2243\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2244\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2245\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   2246\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2247\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/unsloth/models/llama.py\u001b[0m in \u001b[0;36m_fast_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_maybe_log_save_evaluate\u001b[0;34m(self, tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval, start_time)\u001b[0m\n\u001b[1;32m   3091\u001b[0m         \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3092\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_evaluate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3093\u001b[0;31m             \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3094\u001b[0m             \u001b[0mis_new_best_metric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_determine_best_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3095\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_evaluate\u001b[0;34m(self, trial, ignore_keys_for_eval, skip_scheduler)\u001b[0m\n\u001b[1;32m   3045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3046\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_scheduler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3047\u001b[0;31m         \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mignore_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3048\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_report_to_hp_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3049\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   4134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4135\u001b[0m         \u001b[0meval_loop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprediction_loop\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_legacy_prediction_loop\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation_loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4136\u001b[0;31m         output = eval_loop(\n\u001b[0m\u001b[1;32m   4137\u001b[0m             \u001b[0meval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4138\u001b[0m             \u001b[0mdescription\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Evaluation\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mevaluation_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   4328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4329\u001b[0m             \u001b[0;31m# Prediction step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4330\u001b[0;31m             \u001b[0mlosses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprediction_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction_loss_only\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4331\u001b[0m             \u001b[0mmain_input_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"main_input_name\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"input_ids\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4332\u001b[0m             inputs_decode = (\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mprediction_step\u001b[0;34m(self, model, inputs, prediction_loss_only, ignore_keys)\u001b[0m\n\u001b[1;32m   4544\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mhas_labels\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mloss_without_labels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4545\u001b[0m                     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss_context_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4546\u001b[0;31m                         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4547\u001b[0m                     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4548\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/trl/trainer/sft_trainer.py\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(self, model, inputs, return_outputs, num_items_in_batch)\u001b[0m\n\u001b[1;32m    493\u001b[0m         \"\"\"\n\u001b[1;32m    494\u001b[0m         \u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"eval\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_evaluate\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"train\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 495\u001b[0;31m         (loss, outputs) = super().compute_loss(\n\u001b[0m\u001b[1;32m    496\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_items_in_batch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_items_in_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/unsloth/models/_utils.py\u001b[0m in \u001b[0;36m_unsloth_pre_compute_loss\u001b[0;34m(self, model, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1027\u001b[0m         )\n\u001b[1;32m   1028\u001b[0m     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1029\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_old_compute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1030\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(self, model, inputs, return_outputs, num_items_in_batch)\u001b[0m\n\u001b[1;32m   3781\u001b[0m                 \u001b[0mloss_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"num_items_in_batch\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_items_in_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3782\u001b[0m             \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mloss_kwargs\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3783\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3784\u001b[0m         \u001b[0;31m# Save past state if it exists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3785\u001b[0m         \u001b[0;31m# TODO: this needs to be fixed and made cleaner later.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/accelerate/utils/operations.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0;31m# To act like a decorator so that it can be popped when doing `extract_model_from_parallel`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/accelerate/utils/operations.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    805\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mconvert_to_fp32\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getstate__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/accelerate/utils/operations.py\u001b[0m in \u001b[0;36mconvert_to_fp32\u001b[0;34m(tensor)\u001b[0m\n\u001b[1;32m    784\u001b[0m         )\n\u001b[1;32m    785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 786\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrecursively_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_convert_to_fp32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_is_fp16_bf16_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/accelerate/utils/operations.py\u001b[0m in \u001b[0;36mrecursively_apply\u001b[0;34m(func, data, test_type, error_on_other_type, *args, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         return type(data)(\n\u001b[0;32m--> 118\u001b[0;31m             {\n\u001b[0m\u001b[1;32m    119\u001b[0m                 k: recursively_apply(\n\u001b[1;32m    120\u001b[0m                     \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_on_other_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merror_on_other_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/accelerate/utils/operations.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    117\u001b[0m         return type(data)(\n\u001b[1;32m    118\u001b[0m             {\n\u001b[0;32m--> 119\u001b[0;31m                 k: recursively_apply(\n\u001b[0m\u001b[1;32m    120\u001b[0m                     \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_on_other_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merror_on_other_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/accelerate/utils/operations.py\u001b[0m in \u001b[0;36mrecursively_apply\u001b[0;34m(func, data, test_type, error_on_other_type, *args, **kwargs)\u001b[0m\n\u001b[1;32m    124\u001b[0m         )\n\u001b[1;32m    125\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mtest_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0merror_on_other_type\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m         raise TypeError(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/accelerate/utils/operations.py\u001b[0m in \u001b[0;36m_convert_to_fp32\u001b[0;34m(tensor)\u001b[0m\n\u001b[1;32m    776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_convert_to_fp32\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 778\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    779\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_fp16_bf16_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 7.88 GiB. GPU 0 has a total capacity of 14.74 GiB of which 7.74 GiB is free. Process 11128 has 7.00 GiB memory in use. Of the allocated memory 6.82 GiB is allocated by PyTorch, and 26.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
          ]
        }
      ]
    }
  ]
}