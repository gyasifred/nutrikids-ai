# -*- coding: utf-8 -*-
"""self_correction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1WlO3wCsGlAudy0s6qFaWDuAkuOGppYRF
"""

import re
import os
import pandas as pd
import torch
import json
import random
from datasets import Dataset
from unsloth import FastLanguageModel
from trl import SFTTrainer
from transformers import TrainingArguments
from typing import List, Dict, Tuple, Optional
import numpy as np


def extract_malnutrition_result(text):
    """Enhanced extraction of malnutrition=yes/no result with comprehensive pattern matching"""
    if not text or not isinstance(text, str):
        return "no"

    # Convert text to lowercase for case-insensitive matching
    text_lower = text.strip().lower()

    ### PHASE 1: Direct exact format matches at the end

    # Primary pattern: malnutrition=yes/no at end of text
    pattern = r'malnutrition\s*=\s*(yes|no)\s*$'
    match = re.search(pattern, text_lower.replace('\n', ' '))
    if match:
        return match.group(1)

    # Check the last few lines for malnutrition status
    lines = text_lower.split('\n')
    for line in reversed(lines[-7:]):  # Examine last 7 lines
        line = line.strip()

        # Exact format with possible whitespace variations
        exact_patterns = [
            r'^\s*malnutrition\s*=\s*(yes|no)\s*$',
            r'^\s*mal[a-z]*nut[a-z]*\s*=\s*(yes|no)\s*$',
            r'^\s*classification\s*[:=]\s*malnutrition\s*=\s*(yes|no)\s*$',
            r'^\s*final\s*[:=]\s*malnutrition\s*=\s*(yes|no)\s*$'
        ]

        for pattern in exact_patterns:
            match = re.search(pattern, line)
            if match:
                return match.group(1)

    ### PHASE 2: Handle common misspellings and variations

    misspelling_patterns = [
        # Common OCR/typing errors
        (r'mal[a-z]*nut[a-z]*\s*=\s*(yes|no)', 1),
        (r'malnutri[ot]n?\s*=\s*(yes|no)', 1),
        (r'malnourish[a-z]*\s*=\s*(yes|no)', 1),
        (r'mali[a-z]*\s*=\s*(yes|no)', 1),
        (r'malishment\s*=\s*(yes|no)', 1),
        (r'malibration\s*=\s*(yes|no)', 1),
        (r'mal\s*nutrition\s*=\s*(yes|no)', 1),
        # Variations with classification/diagnosis
        (r'(classification|diagnosis)[:\s=]*mal[a-z]*\s*=\s*(yes|no)', 2),
        (r'mal[a-z]*[:\s=]*(yes|no)\s*$', 1),
    ]

    for line in reversed(lines[-10:]):
        line = line.strip()
        for pattern, group_idx in misspelling_patterns:
            match = re.search(pattern, line)
            if match:
                return match.group(group_idx)

    ### PHASE 3: Structured response patterns

    # Look for structured conclusion patterns
    conclusion_patterns = [
        r'final\s+classification[:\s]*malnutrition\s*=\s*(yes|no)',
        r'conclusion[:\s]*malnutrition\s*=\s*(yes|no)',
        r'assessment[:\s]*malnutrition\s*=\s*(yes|no)',
        r'diagnosis[:\s]*malnutrition\s*=\s*(yes|no)',
        r'result[:\s]*malnutrition\s*=\s*(yes|no)'
    ]

    for pattern in conclusion_patterns:
        match = re.search(pattern, text_lower)
        if match:
            return match.group(1)

    ### PHASE 4: Content-based clinical inference

    # Strong positive indicators
    strong_positive = [
        "mild malnutrition", "moderate malnutrition", "severe malnutrition",
        "patient has malnutrition", "diagnosed with malnutrition",
        "evidence of malnutrition", "signs of malnutrition",
        "criteria for malnutrition", "consistent with malnutrition",
        "malnutrition is present", "meets malnutrition criteria",
        "exhibits malnutrition", "indicates malnutrition",
        "confirms malnutrition", "supports malnutrition diagnosis"
    ]

    # Strong negative indicators
    strong_negative = [
        "no malnutrition", "not malnourished", "does not have malnutrition",
        "unlikely to have malnutrition", "no evidence of malnutrition",
        "without malnutrition", "malnutrition is unlikely", "malnutrition is absent",
        "does not meet criteria", "doesn't meet criteria", "not meeting criteria",
        "no signs of malnutrition", "normal nutritional status", "adequate nutrition",
        "rules out malnutrition", "excludes malnutrition"
    ]

    # Uncertainty indicators (default to no)
    uncertainty_indicators = [
        "insufficient evidence", "insufficient data", "insufficient information",
        "can't diagnose", "cannot diagnose", "can not diagnose", "unable to diagnose",
        "not enough evidence", "not enough information", "unclear", "uncertain",
        "indeterminate", "inconclusive", "requires further", "need more"
    ]

    # Count indicators with weighted scoring
    strong_pos_count = sum(2 for indicator in strong_positive if indicator in text_lower)
    strong_neg_count = sum(2 for indicator in strong_negative if indicator in text_lower)
    uncertainty_count = sum(1 for indicator in uncertainty_indicators if indicator in text_lower)

    # Decision logic
    if strong_pos_count > 0 and strong_neg_count == 0 and uncertainty_count == 0:
        return "yes"
    if strong_neg_count > 0 or uncertainty_count > 0:
        return "no"
    if strong_pos_count > strong_neg_count:
        return "yes"

    ### PHASE 5: Clinical numerical indicators

    # Look for Z-scores indicating malnutrition
    z_score_pattern = r'z[-\s]?score[:\s]*[-+]?([0-9]+\.?[0-9]*)'
    z_matches = re.findall(z_score_pattern, text_lower)

    for z_str in z_matches:
        try:
            z_val = float(z_str)
            if z_val <= -2.0:  # Moderate to severe malnutrition threshold
                # Check if this z-score is being described as normal
                if not re.search(r'normal.*z[-\s]?score.*' + z_str, text_lower):
                    return "yes"
        except ValueError:
            continue

    # Look for weight loss percentages
    weight_loss_pattern = r'weight\s+loss[:\s]*([0-9]+\.?[0-9]*)%'
    weight_matches = re.findall(weight_loss_pattern, text_lower)

    for weight_str in weight_matches:
        try:
            weight_loss = float(weight_str)
            if weight_loss >= 5.0:  # 5% weight loss threshold
                return "yes"
        except ValueError:
            continue

    # Look for intake percentages
    intake_pattern = r'intake[:\s]*([0-9]+\.?[0-9]*)%'
    intake_matches = re.findall(intake_pattern, text_lower)

    for intake_str in intake_matches:
        try:
            intake_pct = float(intake_str)
            if intake_pct <= 75.0:  # Less than 75% intake
                return "yes"
        except ValueError:
            continue

    ### PHASE 6: Contextual conclusion analysis

    # Analyze the last 200 characters for final conclusions
    conclusion_text = text_lower[-200:]

    if re.search(r'conclude[ds]?.*malnutrition.*present', conclusion_text):
        return "yes"
    if re.search(r'conclude[ds]?.*no.*malnutrition', conclusion_text):
        return "no"
    if re.search(r'therefore.*malnutrition.*yes', conclusion_text):
        return "yes"
    if re.search(r'therefore.*malnutrition.*no', conclusion_text):
        return "no"

    # Look for definitive statements
    if re.search(r'(diagnosis|assessment|conclusion)[:\s].*malnutrition', conclusion_text):
        if re.search(r'positive|confirmed|present|yes', conclusion_text):
            return "yes"
        if re.search(r'negative|ruled out|absent|no', conclusion_text):
            return "no"

    ### PHASE 7: Fallback patterns

    # Check for any yes/no at the end after malnutrition context
    end_lines = ' '.join(lines[-3:])
    if 'malnutrition' in end_lines:
        if re.search(r'malnutrition.*yes\s*$', end_lines):
            return "yes"
        if re.search(r'malnutrition.*no\s*$', end_lines):
            return "no"

    # Final fallback: look for any clear yes/no statement
    final_line = lines[-1] if lines else ""
    if re.search(r'^\s*(yes|no)\s*$', final_line):
        return final_line.strip()

    # Default to "no" if no clear indication
    return "no"


# Full instruction used in prompt
instruction = """Read the patient's notes and determine if the patient is likely to have malnutrition according to the criteria below.

Malnutrition Classification Criteria:

Mild malnutrition related to undernutrition is usually the result of an acute event, either due to economic circumstances or acute illness, and presents with unintentional weight loss or weight gain velocity less than expected. Moderate malnutrition related to undernutrition occurs due to undernutrition of a significant duration that results in weight-for-length/height values or BMI-for-age values that are below the normal range. Severe malnutrition related to undernutrition occurs as a result of prolonged undernutrition and is most frequently quantified by declines in rates of linear growth that result in stunting.

You should use z scores (also called z for short) for weight-for-height/length, BMI-for-age, length/height-for-age or MUAC criteria. When a child has only one data point in the records (single z score present) use the table below:

Table 1. Single data point present.
Mild Malnutrition
Weight-for-height: −1 to −1.9 z score
BMI-for-age: −1 to −1.9 z score
Length/height-for-age: No Data
Mid–upper arm circumference: Greater than or equal to −1 to −1.9 z score

Moderate Malnutrition
Weight-for-height: −2 to −2.9 z score
BMI-for-age: −2 to −2.9 z score
Length/height-for-age: No Data
Mid–upper arm circumference: Greater than or equal to −2 to −2.9 z score

Severe Malnutrition
Weight-for-height: −3 or greater z score
BMI-for-age: −3 or greater z score
Length/height-for-age: −3 z score
Mid–upper arm circumference: Greater than or equal to −3 z score

When the child has 2 or more data points (multiple z scores over time) use this table:
Table 2. Multiple data points available.
Mild Malnutrition
Weight gain velocity (<2 years of age): Less than 75% of the norm for expected weight gain
Weight loss (2–20 years of age): 5% usual body weight
Deceleration in weight for length/height: Decline of 1 z score
Inadequate nutrient intake: 51%−75% estimated energy/protein need

Moderate Malnutrition
Weight gain velocity (<2 years of age): Less than 50% of the norm for expected weight gain
Weight loss (2–20 years of age): 7.5% usual body weight
Deceleration in weight for length/height: Decline of 2 z score
Inadequate nutrient intake: 26%−50% estimated energy/protein need

Severe Malnutrition
Weight gain velocity (<2 years of age): Less than 25% of the normb for expected weight gain
Weight loss (2–20 years of age): 10% usual body weight
Deceleration in weight for length/height: Decline of 3 z score
Inadequate nutrient intake: less than 25% estimated energy/protein need

====== OUTPUT FORMAT INSTRUCTIONS ======

Provide your analysis in two parts:

PART 1: ANALYSIS
- State whether you used single or multiple data points criteria
- Identify which specific z-scores or criteria you evaluated
- Explain your reasoning for the malnutrition classification
- Keep your explanation brief and focused on clinical findings

PART 2: FINAL CLASSIFICATION
- As the VERY LAST LINE of your response, provide EXACTLY one of these two classifications:
  malnutrition=yes
  malnutrition=no

CRITICAL FORMATTING RULES:
1. Do NOT change the spelling of "malnutrition" - it must be spelled EXACTLY as shown
2. Use EXACTLY the format shown: malnutrition=yes or malnutrition=no
3. No spaces around the equals sign
4. No periods, commas or other punctuation
5. The classification MUST be on its own line at the very end of your response
6. Do NOT explain your final classification - just state it
7. Even if uncertain, you MUST choose either yes or no - do not say "maybe"

====== EXAMPLE RESPONSES ======

EXAMPLE 1:
I used multiple data points for this assessment. The patient shows a weight loss of 6% over the past 3 months, which exceeds the 5% threshold for mild malnutrition. Additionally, the patient's nutrient intake is approximately 60% of estimated needs. Based on Table 2 criteria, these findings are consistent with mild malnutrition.

malnutrition=yes

EXAMPLE 2:
I used a single data point approach. The patient's BMI-for-age z score is -0.8, which is within normal range (above -1.0). The weight-for-height z score is -0.5, also within normal limits. No other indicators of malnutrition are present in the notes.

malnutrition=no

====== EXAMPLE DEMONSTRATIONS ======

### Input:
Patient is a 15-month-old male who presents for routine follow-up. Growth parameters show weight-for-height z-score of -2.3 and BMI-for-age z-score of -2.1. Patient has had poor weight gain over the past 4 months with intake reported as approximately 40% of estimated caloric needs. Physical exam reveals mild wasting and decreased subcutaneous fat. Laboratory values show albumin of 2.8 g/dL.

### Response:
I used a single data point approach combined with additional clinical indicators. The patient's weight-for-height z-score of -2.3 falls within the -2 to -2.9 range, indicating moderate malnutrition according to Table 1. The BMI-for-age z-score of -2.1 also supports this classification. Additionally, the inadequate nutrient intake at 40% of estimated needs (which falls in the 26%-50% range) further confirms moderate malnutrition based on Table 2 criteria.

malnutrition=yes

### Input:
Patient is a 3-year-old female presenting for well-child visit. Growth parameters show weight-for-height z-score of -0.3 and BMI-for-age z-score of 0.1. Height-for-age z-score is -0.5. Patient has been gaining weight appropriately with no recent illnesses. Dietary intake appears adequate with patient eating a varied diet. Physical examination is normal with good muscle tone and appropriate subcutaneous fat distribution. Parents report no feeding concerns.

### Response:
I used a single data point approach. The patient's weight-for-height z-score of -0.3 and BMI-for-age z-score of 0.1 are both within normal range (above -1.0). The height-for-age z-score of -0.5 is also within normal limits. With appropriate weight gain, adequate dietary intake, and normal physical examination findings, there are no indicators suggesting malnutrition.

malnutrition=no"""

# Enhanced self-correction instruction template
self_correction_instruction = """Review your previous analysis and determine if it was correct. If you find any errors in your reasoning or classification, provide a corrected analysis.

SYSTEMATIC REVIEW PROCESS:
1. Clinical Data Verification:
   - Did you correctly identify all relevant z-scores and their values?
   - Did you properly categorize single vs. multiple data point scenarios?
   - Did you miss any weight loss percentages or intake information?

2. Criteria Application Check:
   - Did you use the correct table (Table 1 vs Table 2)?
   - Did you apply the threshold values accurately?
   - Did you consider all relevant clinical indicators?

3. Logical Consistency:
   - Is your final classification consistent with your analysis?
   - Did you properly weigh contradictory evidence?
   - Are there any gaps in your reasoning?

4. Format Compliance:
   - Did you end with the exact format: malnutrition=yes or malnutrition=no?
   - Is the classification on its own line?

If your previous analysis was correct, confirm it briefly. If there were errors, provide the corrected analysis and classification using the same format requirements."""


class EnhancedSelfCorrectionTrainer:
    def __init__(self, model_name: str, max_length: int = 8192):
        self.model_name = model_name
        self.max_length = max_length
        self.model = None
        self.tokenizer = None
        self.extraction_stats = {"successful": 0, "failed": 0, "ambiguous": 0}

    def load_model(self):
        """Load the base model and tokenizer with enhanced configuration"""
        self.model, self.tokenizer = FastLanguageModel.from_pretrained(
            model_name=self.model_name,
            max_seq_length=self.max_length,
            dtype=None,
            load_in_4bit=True
        )

        if self.tokenizer.pad_token is None:
            self.tokenizer.pad_token = self.tokenizer.eos_token

        self.tokenizer.model_max_length = self.max_length
        self.tokenizer.truncation_side = "right"

    def generate_initial_predictions(self, notes: List[str], batch_size: int = 4) -> List[Dict]:
        """Generate initial predictions with enhanced error handling"""
        FastLanguageModel.for_inference(self.model)
        predictions = []

        for i in range(0, len(notes), batch_size):
            batch_notes = notes[i:i+batch_size]
            batch_predictions = []

            for note in batch_notes:
                try:
                    prompt = self.build_prompt(note)

                    # Generate prediction with controlled parameters
                    inputs = self.tokenizer(prompt, return_tensors="pt", truncation=True, max_length=self.max_length)

                    with torch.no_grad():
                        outputs = self.model.generate(
                            **inputs,
                            max_new_tokens=512,
                            temperature=0.3,  # Lower temperature for more consistent outputs
                            do_sample=True,
                            pad_token_id=self.tokenizer.eos_token_id,
                            repetition_penalty=1.1,
                            top_p=0.9
                        )

                    # Decode the generated response
                    generated_text = self.tokenizer.decode(outputs[0], skip_special_tokens=True)
                    response = generated_text[len(prompt):].strip()

                    classification = self.extract_classification(response)

                    batch_predictions.append({
                        'note': note,
                        'prompt': prompt,
                        'initial_response': response,
                        'initial_classification': classification,
                        'extraction_confidence': self.assess_extraction_confidence(response, classification)
                    })

                except Exception as e:
                    print(f"Error generating prediction: {e}")
                    batch_predictions.append({
                        'note': note,
                        'prompt': self.build_prompt(note),
                        'initial_response': f"Error generating response: {e}",
                        'initial_classification': 'no',
                        'extraction_confidence': 'low'
                    })

            predictions.extend(batch_predictions)

        return predictions

    def extract_classification(self, response: str) -> str:
        """Use the enhanced extraction function"""
        result = extract_malnutrition_result(response)

        # Update statistics
        if result in ['yes', 'no']:
            if 'malnutrition=' in response.lower():
                self.extraction_stats["successful"] += 1
            else:
                self.extraction_stats["ambiguous"] += 1
        else:
            self.extraction_stats["failed"] += 1

        return result

    def assess_extraction_confidence(self, response: str, classification: str) -> str:
        """Assess confidence in extraction result"""
        response_lower = response.lower()

        # High confidence: exact format found
        if re.search(r'malnutrition\s*=\s*(yes|no)', response_lower):
            return 'high'

        # Medium confidence: clear clinical conclusion
        positive_indicators = ['malnutrition is present', 'has malnutrition', 'diagnosed with malnutrition']
        negative_indicators = ['no malnutrition', 'not malnourished', 'normal nutritional status']

        if any(indicator in response_lower for indicator in positive_indicators + negative_indicators):
            return 'medium'

        # Low confidence: inference based
        return 'low'

    def build_prompt(self, note: str) -> str:
        """Build the standard prompt with enhanced formatting"""
        return f"### Instruction:\n{instruction}\n\n### Input:\n{note.strip()}\n\n### Response:"

    def build_correction_prompt(self, note: str, initial_response: str, true_label: str = None) -> str:
        """Build enhanced prompt for self-correction"""
        correction_prompt = f"""### Instruction:
{instruction}

### Input:
{note.strip()}

### Previous Response:
{initial_response}

### Self-Correction Task:
{self_correction_instruction}

### Corrected Response:"""
        return correction_prompt

    def create_self_correction_examples(self, data: pd.DataFrame,
                                     initial_predictions: List[Dict],
                                     correction_ratio: float = 0.3,
                                     prioritize_low_confidence: bool = True) -> List[Dict]:
        """Create enhanced self-correction training examples"""
        correction_examples = []

        for i, (_, row) in enumerate(data.iterrows()):
            if i >= len(initial_predictions):
                break

            pred_data = initial_predictions[i]
            true_label = str(row['label']).strip().lower()
            true_label = 'yes' if true_label in ['yes', '1', '1.0', 'true', 'positive'] else 'no'

            initial_pred = pred_data['initial_classification']
            confidence = pred_data.get('extraction_confidence', 'medium')

            # Enhanced correction logic
            should_correct = False
            correction_type = None

            # Always correct wrong predictions
            if initial_pred != true_label:
                should_correct = True
                correction_type = 'error_correction'

            # Prioritize low confidence correct predictions for reinforcement
            elif confidence == 'low' and random.random() < correction_ratio * 2:
                should_correct = True
                correction_type = 'confidence_reinforcement'

            # Include some high-confidence correct predictions for stability
            elif confidence == 'high' and random.random() < correction_ratio * 0.5:
                should_correct = True
                correction_type = 'stability_reinforcement'

            # Regular reinforcement for medium confidence
            elif confidence == 'medium' and random.random() < correction_ratio:
                should_correct = True
                correction_type = 'standard_reinforcement'

            if should_correct:
                corrected_response = self.create_corrected_response(
                    pred_data['note'], pred_data['initial_response'], true_label, correction_type
                )

                correction_prompt = self.build_correction_prompt(
                    pred_data['note'], pred_data['initial_response']
                )

                correction_examples.append({
                    'prompt': correction_prompt,
                    'response': corrected_response,
                    'note': pred_data['note'],
                    'initial_pred': initial_pred,
                    'true_label': true_label,
                    'correction_type': correction_type,
                    'confidence': confidence
                })

        return correction_examples

    def create_corrected_response(self, note: str, initial_response: str, true_label: str, correction_type: str) -> str:
        """Create enhanced corrected responses based on correction type"""

        if correction_type == 'error_correction':
            if true_label == 'yes':
                correction = f"""Upon systematic review of my previous analysis, I identified several critical errors:

My previous response failed to properly recognize key malnutrition indicators present in the clinical data. Let me provide a corrected analysis:

{self.generate_clinical_analysis(note, true_label)}

The evidence clearly supports malnutrition classification based on the established clinical criteria.

malnutrition=yes"""
            else:
                correction = f"""Upon systematic review of my previous analysis, I found errors in my clinical interpretation:

My previous response incorrectly identified malnutrition indicators. Let me provide a corrected analysis:

{self.generate_clinical_analysis(note, true_label)}

The clinical data does not meet the criteria for malnutrition diagnosis.

malnutrition=no"""

        elif correction_type == 'confidence_reinforcement':
            correction = f"""Upon review of my previous analysis, while my classification was correct, I can provide a more confident and thorough explanation:

{self.generate_clinical_analysis(note, true_label)}

This reinforces my original classification with greater clinical clarity.

malnutrition={true_label}"""

        else:  # stability_reinforcement or standard_reinforcement
            correction = f"""Upon systematic review of my previous analysis, I confirm that my reasoning and classification were accurate:

{self.generate_clinical_analysis(note, true_label)}

The analysis properly applied the malnutrition classification criteria and the evidence supports this conclusion.

malnutrition={true_label}"""

        return correction

    def generate_clinical_analysis(self, note: str, true_label: str) -> str:
        """Generate clinically-informed analysis based on note content"""
        # Extract key clinical indicators from the note
        indicators = self.extract_comprehensive_indicators(note)

        if true_label == 'yes':
            analysis_parts = []

            if indicators['z_scores']:
                z_scores = [float(z) for z in indicators['z_scores'] if self.is_valid_z_score(z)]
                significant_z = [z for z in z_scores if z <= -1.0]
                if significant_z:
                    analysis_parts.append(f"The documented z-scores {significant_z} fall below normal thresholds, indicating malnutrition severity according to clinical criteria.")

            if indicators['weight_loss']:
                analysis_parts.append(f"Weight loss indicators ({indicators['weight_loss']}) exceed the clinical thresholds for malnutrition classification.")

            if indicators['intake_deficiency']:
                analysis_parts.append(f"Inadequate nutrient intake documented ({indicators['intake_deficiency']}) falls within malnutrition criteria ranges.")

            if not analysis_parts:
                analysis_parts.append("Multiple clinical indicators in the documentation support malnutrition classification when properly evaluated against established criteria.")

            return " ".join(analysis_parts)

        else:  # true_label == 'no'
            analysis_parts = []

            if indicators['z_scores']:
                z_scores = [float(z) for z in indicators['z_scores'] if self.is_valid_z_score(z)]
                normal_z = [z for z in z_scores if z > -1.0]
                if normal_z:
                    analysis_parts.append(f"The documented z-scores {normal_z} fall within normal ranges (above -1.0 threshold).")

            analysis_parts.append("Clinical documentation shows growth parameters, nutritional intake, and physical findings within normal limits.")
            analysis_parts.append("No indicators meet the established criteria for malnutrition classification.")

            return " ".join(analysis_parts)

    def extract_comprehensive_indicators(self, note: str) -> Dict:
        """Extract comprehensive clinical indicators from note"""
        indicators = {
            'z_scores': [],
            'weight_loss': [],
            'intake_deficiency': [],
            'physical_findings': [],
            'age_info': None
        }

        note_lower = note.lower()

        # Extract z-scores with improved patterns
        z_patterns = [
            r'z[-\s]?score[:\s]*[-+]?(\d+\.?\d*)',
            r'weight[-\s]for[-\s]height[:\s]*z[-\s]?score[:\s]*[-+]?(\d+\.?\d*)',
            r'bmi[-\s]for[-\s]age[:\s]*z[-\s]?score[:\s]*[-+]?(\d+\.?\d*)',
            r'z[-\s]?score[:\s]*of[-\s]*[-+]?(\d+\.?\d*)'
        ]

        for pattern in z_patterns:
            matches = re.findall(pattern, note_lower)
            indicators['z_scores'].extend(matches)

        # Extract weight loss information
        weight_patterns = [
            r'weight\s+loss[:\s]*(\d+\.?\d*)%?',
            r'lost[:\s]*(\d+\.?\d*)%?\s*weight',
            r'(\d+\.?\d*)%\s*weight\s*loss'
        ]

        for pattern in weight_patterns:
            matches = re.findall(pattern, note_lower)
            indicators['weight_loss'].extend(matches)

       # Extract intake information
        intake_patterns = [
            r'intake[:\s]*(\d+\.?\d*)%',                    # "intake: 75%" or "intake 80.5%"
            r'(\d+\.?\d*)%\s*of\s*estimated\s*needs',      # "85% of estimated needs"
            r'eating[:\s]*(\d+\.?\d*)%',                    # "eating: 60%" or "eating 70.2%"
            r'consumed[:\s]*(\d+\.?\d*)%',                  # "consumed: 90%"
            r'(\d+\.?\d*)%\s*intake',                       # "75% intake"
            r'(\d+\.?\d*)%\s*consumption',                  # "80% consumption"
            r'oral\s*intake[:\s]*(\d+\.?\d*)%',            # "oral intake: 85%"
            r'food\s*intake[:\s]*(\d+\.?\d*)%',            # "food intake: 70%"
        ]

        for pattern in intake_patterns:
            matches = re.findall(pattern, note_lower)
            indicators['intake_deficiency'].extend(matches)

        # Extract age information
        age_patterns = [
            r'(\d+)[-\s]?(month|year)s?[-\s]?old',
            r'age[:\s]*(\d+)[-\s]?(month|year)s?',
            r'(\d+)[-\s]?(mo|yr)s?[-\s]?old'
        ]

        for pattern in age_patterns:
            matches = re.findall(pattern, note_lower)
            if matches:
                indicators['age_info'] = matches[0]
                break

        # Extract physical findings
        physical_patterns = [
            r'wasting', r'decreased subcutaneous fat', r'muscle wasting',
            r'poor muscle tone', r'appropriate subcutaneous fat', r'normal muscle tone'
        ]

        for pattern in physical_patterns:
            if pattern in note_lower:
                indicators['physical_findings'].append(pattern)

        return indicators

    def is_valid_z_score(self, z_str: str) -> bool:
        """Check if z-score string is valid"""
        try:
            z_val = float(z_str)
            return -10.0 <= z_val <= 10.0  # Reasonable z-score range
        except (ValueError, TypeError):
            return False

    def create_combined_dataset(self, original_data: List[Dict],
                              correction_data: List[Dict],
                              correction_weight: float = 0.4) -> List[Dict]:
        """Combine original and correction data with appropriate weighting"""
        combined_data = []

        # Add original data
        combined_data.extend(original_data)

        # Add correction data (potentially multiple times for emphasis)
        if correction_data:
            correction_repeats = max(1, int(len(original_data) * correction_weight / len(correction_data)))

            for _ in range(correction_repeats):
                combined_data.extend(correction_data)

        # Shuffle the combined dataset
        random.shuffle(combined_data)

        return combined_data

def preprocess_clinical_note(note_text):
    """Enhanced preprocessing that keeps clinical data intact while removing problematic patterns."""
    if not note_text:
        return ""

    # Preserve clinical abbreviations and numbers while removing artifacts
    note_text = re.sub(r'[*_\-=+#~^`]{2,}', ' ', note_text)  # Remove repeating special chars
    note_text = re.sub(r'<[^>]+>', ' ', note_text)           # Remove HTML/XML tags
    note_text = re.sub(r'\s{2,}', ' ', note_text)            # Normalize whitespace

    # Handle special tokens without affecting clinical content
    note_text = note_text.replace('</s>', '\n\n')
    special_tokens = ['<s>', '<pad>', '</pad>', '<eos>', '<bos>']
    for token in special_tokens:
        note_text = note_text.replace(token, ' ')

    return note_text.strip()

def train_malnutrition_model_with_enhanced_self_correction(
    data_path: str,
    model_name: str = "unsloth/meta-llama-3.1-8b-unsloth-bnb-4bit",
    output_dir: str = "./malnutrition_models",
    max_length: int = 8192,
    num_epochs: int = 3,
    batch_size: int = 4,
    correction_ratio: float = 0.3,
    correction_weight: float = 0.4,
    self_correction_epochs: int = 2
):
    """
    Train a malnutrition classification model with enhanced self-correction training

    Parameters:
    -----------
    data_path : str
        Path to the CSV file containing the training data
    model_name : str
        Name of the pretrained model to load
    output_dir : str
        Directory to save the trained model
    max_length : int
        Maximum sequence length for tokenization
    num_epochs : int
        Number of initial training epochs
    batch_size : int
        Batch size for training
    correction_ratio : float
        Ratio of correct predictions to include in correction training
    correction_weight : float
        Weight given to correction examples in the combined dataset
    self_correction_epochs : int
        Number of additional epochs for self-correction training
    """

    # Create output directory
    os.makedirs(output_dir, exist_ok=True)

    # Load and prepare dataset
    try:
        df = pd.read_csv(data_path, usecols=['DEID','txt','label'])
        print(f"Loaded dataset with {len(df)} examples")
    except Exception as e:
        print(f"Error loading dataset: {e}")
        return None

    # Preprocess data
    df["txt"] = df["txt"].fillna("").apply(preprocess_clinical_note)
    df["label"] = df["label"].fillna("no")

    # Create train/validation split
    dataset = Dataset.from_pandas(df)
    dataset_dict = dataset.train_test_split(test_size=0.1, seed=3407)
    train_dataset = dataset_dict["train"]
    eval_dataset = dataset_dict["test"]

    print(f"Training set: {len(train_dataset)} examples")
    print(f"Validation set: {len(eval_dataset)} examples")

    # Initialize enhanced self-correction trainer
    sc_trainer = EnhancedSelfCorrectionTrainer(model_name, max_length)
    sc_trainer.load_model()

    # Prepare model for training
    model = FastLanguageModel.get_peft_model(
        sc_trainer.model,
        r=16,
        target_modules=["q_proj", "k_proj", "v_proj", "o_proj", "gate_proj", "up_proj", "down_proj"],
        lora_alpha=32,
        lora_dropout=0,
        bias="none",
        use_gradient_checkpointing="unsloth",
        random_state=3407,
        use_rslora=False,
        loftq_config=None,
    )

    # PHASE 1: Initial training on original data
    print("=" * 60)
    print("PHASE 1: Initial Training")
    print("=" * 60)

    def format_original_example(example):
        prompt = f"### Instruction:\n{instruction}\n\n### Input:\n{example['txt']}\n\n### Response:"
        label = str(example.get("label", "no")).strip().lower()
        if label not in ["yes", "no"]:
            positive_indicators = ["1", "1.0", "true", "positive", "y"]
            label = "yes" if any(str(label) == ind for ind in positive_indicators) else "no"
        response = f"malnutrition={label}"
        return {"text": f"{prompt}\n{response}{sc_trainer.tokenizer.eos_token}"}

    # Process original training data
    train_formatted = train_dataset.map(format_original_example)

    # Initial training
    training_args = TrainingArguments(
        per_device_train_batch_size=batch_size,
        per_device_eval_batch_size=batch_size,
        gradient_accumulation_steps=1,
        warmup_ratio=0.1,
        num_train_epochs=num_epochs,
        learning_rate=2e-5,
        fp16=not torch.cuda.is_bf16_supported(),
        bf16=torch.cuda.is_bf16_supported(),
        logging_steps=10,
        optim="adamw_8bit",
        weight_decay=0.1,
        lr_scheduler_type="linear",
        seed=3407,
        report_to="none",
        output_dir=os.path.join(output_dir, "phase1"),
        dataloader_drop_last=True,
        remove_unused_columns=False
    )

    trainer = SFTTrainer(
        model=model,
        train_dataset=train_formatted,
        processing_class=sc_trainer.tokenizer,
        max_seq_length=max_length,
        dataset_text_field="text",
        packing=True,
        args=training_args,
    )

    print("Starting initial training...")
    trainer.train()

    # PHASE 2: Generate predictions for self-correction
    print("=" * 60)
    print("PHASE 2: Generating Self-Correction Data")
    print("=" * 60)

    # Generate initial predictions on training data
    train_notes = [example['txt'] for example in train_dataset]
    print("Generating initial predictions...")
    initial_predictions = sc_trainer.generate_initial_predictions(train_notes[:200], batch_size=2)  # Process more examples

    # Create self-correction examples
    print("Creating self-correction examples...")
    correction_examples = sc_trainer.create_self_correction_examples(
        df.head(200), initial_predictions, correction_ratio, prioritize_low_confidence=True
    )

    print(f"Created {len(correction_examples)} self-correction examples")
    print(f"Extraction statistics: {sc_trainer.extraction_stats}")

    # PHASE 3: Self-correction training
    print("=" * 60)
    print("PHASE 3: Enhanced Self-Correction Training")
    print("=" * 60)

    # Format correction examples
    def format_correction_example(example):
        return {"text": f"{example['prompt']}\n{example['response']}{sc_trainer.tokenizer.eos_token}"}

    correction_dataset = Dataset.from_list(correction_examples)
    correction_formatted = correction_dataset.map(format_correction_example)

    # Combine original and correction data
    original_examples = [{"text": ex["text"]} for ex in train_formatted]
    correction_examples_formatted = [{"text": ex["text"]} for ex in correction_formatted]

    combined_examples = sc_trainer.create_combined_dataset(
        original_examples, correction_examples_formatted, correction_weight
    )

    combined_dataset = Dataset.from_list(combined_examples)

    print(f"Combined dataset size: {len(combined_dataset)} examples")

    # Self-correction training with adjusted parameters
    correction_training_args = TrainingArguments(
        per_device_train_batch_size=batch_size,
        per_device_eval_batch_size=batch_size,
        gradient_accumulation_steps=2,  # Increase for stability
        warmup_ratio=0.05,
        num_train_epochs=self_correction_epochs,
        learning_rate=1e-5,  # Lower learning rate for fine-tuning
        fp16=not torch.cuda.is_bf16_supported(),
        bf16=torch.cuda.is_bf16_supported(),
        logging_steps=5,
        optim="adamw_8bit",
        weight_decay=0.01,  # Reduced weight decay
        lr_scheduler_type="cosine",  # Changed to cosine schedule
        seed=3407,
        report_to="none",
        output_dir=os.path.join(output_dir, "phase2"),
        dataloader_drop_last=True,
        remove_unused_columns=False,
        save_strategy="steps",
        save_steps=50,
        evaluation_strategy="no"
    )

    correction_trainer = SFTTrainer(
        model=model,
        train_dataset=combined_dataset,
        processing_class=sc_trainer.tokenizer,
        max_seq_length=max_length,
        dataset_text_field="text",
        packing=True,
        args=correction_training_args,
    )

    print("Starting enhanced self-correction training...")
    correction_trainer.train()

    # Save the final model
    save_path = f"{output_dir}/final_enhanced_model"
    model.save_pretrained_merged(
        save_path,
        sc_trainer.tokenizer,
        save_method="merged_16bit"
    )

    # Save enhanced configuration and metadata
    config = {
        "model_name": model_name,
        "max_length": max_length,
        "instruction": instruction,
        "training_phases": {
            "phase1_epochs": num_epochs,
            "phase2_epochs": self_correction_epochs,
            "correction_ratio": correction_ratio,
            "correction_weight": correction_weight,
            "prioritize_low_confidence": True
        },
        "correction_examples_created": len(correction_examples),
        "final_dataset_size": len(combined_dataset),
        "extraction_statistics": sc_trainer.extraction_stats,
        "correction_type_distribution": {
            correction_type: sum(1 for ex in correction_examples if ex.get('correction_type') == correction_type)
            for correction_type in ['error_correction', 'confidence_reinforcement', 'stability_reinforcement', 'standard_reinforcement']
        }
    }

    with open(os.path.join(output_dir, "enhanced_training_config.json"), "w") as f:
        json.dump(config, f, indent=2)

    # Save correction examples for analysis
    correction_sample = []
    for correction_type in ['error_correction', 'confidence_reinforcement', 'stability_reinforcement']:
        type_examples = [ex for ex in correction_examples if ex.get('correction_type') == correction_type]
        correction_sample.extend(type_examples[:3])  # Save 3 examples of each type

    with open(os.path.join(output_dir, "enhanced_correction_examples.json"), "w") as f:
        json.dump(correction_sample, f, indent=2)

    print(f"Enhanced model successfully saved to {save_path}")
    print(f"Enhanced self-correction training completed!")
    print(f"Final extraction success rate: {sc_trainer.extraction_stats['successful'] / (sc_trainer.extraction_stats['successful'] + sc_trainer.extraction_stats['failed'] + sc_trainer.extraction_stats['ambiguous']) * 100:.1f}%")

    return model, sc_trainer.tokenizer

if __name__ == "__main__":
    # Configuration parameters
    data_path = "data/notes_train.csv"
    model_name = "unsloth/mistral-7b-instruct-v0.3-bnb-4bit"
    output_dir = "./mistral-7b-malnutrition-self-correction"
    max_length = 32000
    num_epochs = 5
    batch_size = 1

    # Enhanced self-correction parameters
    correction_ratio = 0.4  # Include 40% of correct predictions in correction training
    correction_weight = 0.5  # Correction examples make up 50% of combined dataset
    self_correction_epochs = 3  # Additional epochs for self-correction

    os.makedirs(output_dir, exist_ok=True)

    print(f"Starting enhanced self-correction training using {model_name}...")
    model, tokenizer = train_malnutrition_model_with_enhanced_self_correction(
        data_path=data_path,
        model_name=model_name,
        output_dir=output_dir,
        max_length=max_length,
        num_epochs=num_epochs,
        batch_size=batch_size,
        correction_ratio=correction_ratio,
        correction_weight=correction_weight,
        self_correction_epochs=self_correction_epochs
    )

    print("Enhanced self-correction training completed successfully!")
